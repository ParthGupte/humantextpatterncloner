{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tovzZ9v53b66"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as ke\n",
        "import numpy as np\n",
        "import random as rd\n",
        "\n",
        "vocab_size = 10000\n",
        "dim = 200\n",
        "no_ofppl = 20\n",
        "input_sentsize = 30\n",
        "input_size_bot = dim*input_sentsize + no_ofppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRNnVPLW_b5Q"
      },
      "outputs": [],
      "source": [
        "#word2vec\n",
        "\n",
        "def word2vec(vocab_size = vocab_size,h_size = dim):\n",
        "    model = ke.Sequential()\n",
        "    model.add(ke.layers.Dense(h_size, input_shape = (vocab_size,)))\n",
        "    model.add(ke.layers.Dense(vocab_size,activation = ke.activations.softmax))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhoJOVY5P4of"
      },
      "outputs": [],
      "source": [
        "#model creation\n",
        "word2vec_model = word2vec()\n",
        "word2vec_model.compile(loss=\"categorical_crossentropy\",optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "HjHizSNPQhRO",
        "outputId": "fa555c95-baa1-43dd-868d-f409f3aaf0a5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1c57caff7671>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mchoicelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoicelist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mchoicelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
          ]
        }
      ],
      "source": [
        "#training loop\n",
        "\n",
        "X = np.load(\"X.npy\")\n",
        "Y = np.load(\"Y.npy\")\n",
        "\n",
        "n = X.shape[0]\n",
        "\n",
        "no_of_epochs = 100\n",
        "batch_size = 50\n",
        "\n",
        "word2vec_model.fit(X,Y,epochs = no_of_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR-ZQmlCVgB8"
      },
      "outputs": [],
      "source": [
        "word2vec_layer = word2vec_model.layers[0]\n",
        "word2vec_layer.trainable = False\n",
        "\n",
        "def tokens_to_vecs(sent:list,layer):\n",
        "    onehot_list = []\n",
        "    for word in sent:\n",
        "        onehot_list.append(onehot(word))\n",
        "    onehot_array = np.array(onehot_list)\n",
        "    vec_array = layer.predict(onehot_array)\n",
        "    return vec_array\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
